{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import linprog\n",
    "from math import sqrt\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import math\n",
    "import matplotlib.pyplot as plt \n",
    "import timeit\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import time\n",
    "\n",
    "from cvxopt import matrix, solvers\n",
    "from cvxopt.modeling import variable\n",
    "from cvxopt.modeling import op, dot\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# notes\n",
    "\n",
    "# The get_demand_matrix function has some hard-coded stuff that needs to be modified if # treatments != 2 \n",
    "# -- create a variable for each treatment and make the process programmatic\n",
    "\n",
    "# changed from np.array() to lists up to clearing error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hardcoded constants\n",
    "\n",
    "num_subjects = 1540 # i\n",
    "num_treatments = 2 # t\n",
    "capacity_matrix = [663, 877]\n",
    "budget = 100\n",
    "epsilon = 0.1 # has to be less than 0.5\n",
    "rct_treatment_probabilities = [(capacity_matrix[0]*1.0)/(num_subjects), (capacity_matrix[1]*1.0)/(num_subjects)]\n",
    "budget_matrix = [budget] * num_subjects\n",
    "\n",
    "# Scaling factor for alpha, beta to set new prices\n",
    "alpha_scaling_factor = 0.75\n",
    "beta_scaling_factor = budget/50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Init alpha, beta assumed to be positive\n",
    "def init_alpha():\n",
    "    alpha = [random.randint(-budget, 0) for i in range(num_treatments)]\n",
    "    return alpha\n",
    "def init_beta():\n",
    "    beta = [random.randint(-budget, budget) for i in range(num_treatments)]\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Price vector pi(i,t) = alpha(t) * pte(i,t) + beta(t). Dimensions num_subjects * num_treatments\n",
    "def get_price_matrix(alpha, beta):\n",
    "    price_matrix = [[(alpha[t] * pte_it + beta[t]) for t, pte_it in enumerate(pte_row)] for pte_row in pte_matrix]\n",
    "    #print \"get_price_matrix: Price matrix:\", price_matrix\n",
    "    return price_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_demand_matrix(price_matrix):\n",
    "    demand_matrix = np.zeros((num_subjects, num_treatments)).tolist()\n",
    "    # solve LP problem subject by subject\n",
    "    for i in range(num_subjects):\n",
    "        p_i0 = variable()\n",
    "        p_i1 = variable()\n",
    "\n",
    "        objective = wtp_matrix[i][0]*p_i0 + wtp_matrix[i][1]*p_i1\n",
    "        budget_constraint = (price_matrix[i][0]*p_i0 + price_matrix[i][1]*p_i1 <= budget_matrix[i])\n",
    "        probability_constraint = (p_i0 + p_i1 == 1)\n",
    "        b1 = (p_i0 >= epsilon)\n",
    "        b2 = (p_i0 <= 1-epsilon)\n",
    "        b3 = (p_i1 >= epsilon)\n",
    "        b4 = (p_i1 <= 1-epsilon)\n",
    "\n",
    "        lp_subject = op(objective, [budget_constraint, probability_constraint, b1, b2, b3, b4])\n",
    "        solvers.options['show_progress'] = False\n",
    "        sol = lp_subject.solve()\n",
    "        \n",
    "        demand_matrix[i][0] = p_i0.value[0]\n",
    "        demand_matrix[i][1] = p_i1.value[0]\n",
    "    \n",
    "    return demand_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Excess_demand(t) = treatment_demand(t) - capacity(t). Dimensions 1 * num_treatments\n",
    "# Treatment_demand(t) = sum of demand(t) across all i. Dimensions 1 * num_treatments\n",
    "def get_excess_demand_matrix(demand_matrix):\n",
    "    treatment_demand_matrix = np.zeros(num_treatments)\n",
    "    excess_demand_matrix = np.zeros(num_treatments)\n",
    "    for subject in range(num_subjects):\n",
    "        for treatment in range(num_treatments):\n",
    "            treatment_demand_matrix[treatment] += demand_matrix[subject][treatment]\n",
    "    excess_demand_matrix = treatment_demand_matrix - capacity_matrix\n",
    "    #print \"get_excess_demand_matrix: Excess demand matrix:\", excess_demand_matrix\n",
    "    return excess_demand_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clearing error in market = sqrt(sum of excess_demand(t)^2 for every treatment t)\n",
    "def get_clearing_error(excess_demand_matrix):\n",
    "    # If demand is satisfied everywhere and total capacity > number of subjects, no clearing error\n",
    "    if all(excess <= 0 for excess in excess_demand_matrix):\n",
    "        print \"get_clearing_error: Market clear, no clearing error!\"\n",
    "        return 0\n",
    "    else:\n",
    "        clearing_error = sqrt(sum([excess**2 for excess in excess_demand_matrix])) / sum(capacity_matrix)\n",
    "        print \"get_clearing_error: Clearing error:\", clearing_error\n",
    "        return clearing_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Recalibrate alpha, beta values to set new prices\n",
    "def get_alpha_new(alpha, excess_demand_matrix):\n",
    "    alpha_new = alpha + excess_demand_matrix * alpha_scaling_factor\n",
    "    for (i, a) in enumerate(alpha_new):\n",
    "        if (a > 0):\n",
    "            # alpha become +ve, so reset to random initialization\n",
    "            alpha_new[i] = random.randint(-budget, 0)\n",
    "    return alpha_new.tolist()\n",
    "\n",
    "def get_beta_new(beta, excess_demand_matrix):\n",
    "    beta_new = beta + excess_demand_matrix * beta_scaling_factor\n",
    "    return beta_new.tolist()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find market clearing price vector. The objective is to change alpha and beta values so that we reduce clearing error\n",
    "def clear_market():\n",
    "    # Initialize market prices and demand\n",
    "    alpha = init_alpha()\n",
    "    beta = init_beta()    \n",
    "    price_matrix = get_price_matrix(alpha, beta)\n",
    "    demand_matrix = get_demand_matrix(price_matrix)  \n",
    "    excess_demand_matrix = get_excess_demand_matrix(demand_matrix)\n",
    "    clearing_error = get_clearing_error(excess_demand_matrix)\n",
    "        \n",
    "    # clearing error is percentage of total capacity so we want the market to clear at 1%\n",
    "    minimum_clearing_error = clearing_error\n",
    "    clearing_error_threshold = 0.01\n",
    "    threshold_iterations = 10\n",
    "    iterations = 0\n",
    "    alpha_star = 0\n",
    "    beta_star = 0\n",
    "    \n",
    "    # Set new prices to clear market\n",
    "    while True:\n",
    "        if iterations > threshold_iterations:\n",
    "            # new search start\n",
    "            alpha = init_alpha()\n",
    "            beta = init_beta()\n",
    "            iterations = 0\n",
    "            print \"new search start\"\n",
    "        else:\n",
    "            # continue down current search\n",
    "            alpha = get_alpha_new(alpha, excess_demand_matrix)\n",
    "            beta = get_beta_new(beta, excess_demand_matrix)\n",
    "        \n",
    "        price_matrix = get_price_matrix(alpha, beta)\n",
    "        demand_matrix = get_demand_matrix(price_matrix)\n",
    "        excess_demand_matrix = get_excess_demand_matrix(demand_matrix)\n",
    "        clearing_error = get_clearing_error(excess_demand_matrix)\n",
    "        \n",
    "        # Store parameter values for minimum clearing error\n",
    "        if clearing_error < minimum_clearing_error:\n",
    "            minimum_clearing_error = clearing_error\n",
    "            alpha_star = copy.copy(alpha)\n",
    "            beta_star = copy.copy(beta)\n",
    "        # cleared the market! \n",
    "        if minimum_clearing_error < clearing_error_threshold:\n",
    "            break\n",
    "        iterations += 1\n",
    "    \n",
    "    print \"Minimum clearing error:\", minimum_clearing_error\n",
    "    print \"Alpha_star:\", alpha_star\n",
    "    print \"Beta star:\", beta_star\n",
    "    return (minimum_clearing_error, alpha_star, beta_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simulate():\n",
    "    while True: \n",
    "        min_error, alpha_star, beta_star = clear_market()\n",
    "        price_star = get_price_matrix(alpha_star, beta_star)\n",
    "        demand_star = get_demand_matrix(price_star)\n",
    "        \n",
    "        control_probs = [demand_star_i[0] for demand_star_i in demand_star]\n",
    "        treatment_probs = [demand_star_i[1] for demand_star_i in demand_star]\n",
    "        \n",
    "        if (min_error < 0.01):\n",
    "            print \"cleared market!\"\n",
    "            break\n",
    "    return demand_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_clearing_error: Clearing error: 0.383306976841\n",
      "get_clearing_error: Clearing error: 0.0280557727012\n",
      "get_clearing_error: Clearing error: 0.0232314177542\n",
      "get_clearing_error: Clearing error: 0.0196872995453\n",
      "get_clearing_error: Clearing error: 0.0169556322031\n",
      "get_clearing_error: Clearing error: 0.0147784716608\n",
      "get_clearing_error: Clearing error: 0.012999864796\n",
      "get_clearing_error: Clearing error: 0.0115190472363\n",
      "get_clearing_error: Clearing error: 0.0102675476173\n",
      "get_clearing_error: Clearing error: 0.00919695598874\n",
      "Minimum clearing error: 0.00919695598874\n",
      "Alpha_star: [-13.59331993265647, -460.3433576541506]\n",
      "Beta star: [1156.24895374437, -1200.2489537444017]\n",
      "cleared market!\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "finished dataset 1\n",
      "get_clearing_error: Clearing error: 0.184582442748\n",
      "get_clearing_error: Clearing error: 0.132262480959\n",
      "get_clearing_error: Clearing error: 0.139653914936\n",
      "get_clearing_error: Clearing error: 0.136278314383\n",
      "get_clearing_error: Clearing error: 0.116005822822\n",
      "get_clearing_error: Clearing error: 0.124427301376\n",
      "get_clearing_error: Clearing error: 0.179992194859\n",
      "get_clearing_error: Clearing error: 0.152328818846\n",
      "get_clearing_error: Clearing error: 0.0210831484521\n",
      "get_clearing_error: Clearing error: 0.0364127069545\n",
      "get_clearing_error: Clearing error: 0.0893034347823\n",
      "get_clearing_error: Clearing error: 0.108035243645\n",
      "new search start\n",
      "get_clearing_error: Clearing error: 0.184582407691\n",
      "get_clearing_error: Clearing error: 0.0384513339584\n",
      "get_clearing_error: Clearing error: 0.00843238082185\n",
      "Minimum clearing error: 0.00843238082185\n",
      "Alpha_star: [-141.34646552096234, -104.40352483070563]\n",
      "Beta star: [-412.25724138923295, 281.25724138927353]\n",
      "cleared market!\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "finished dataset 2\n",
      "get_clearing_error: Clearing error: 0.381103005168\n",
      "get_clearing_error: Clearing error: 0.00132186028007\n",
      "Minimum clearing error: 0.00132186028007\n",
      "Alpha_star: [-34.0, -316.2499997736943]\n",
      "Beta star: [905.999999396503, -866.9999993965181]\n",
      "cleared market!\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "finished dataset 3\n",
      "get_clearing_error: Clearing error: 0.427386396121\n",
      "get_clearing_error: Clearing error: 0.0503663619044\n",
      "get_clearing_error: Clearing error: 0.0425278910188\n",
      "get_clearing_error: Clearing error: 0.0370710626924\n",
      "get_clearing_error: Clearing error: 0.0329830065094\n",
      "get_clearing_error: Clearing error: 0.0297709482163\n",
      "get_clearing_error: Clearing error: 0.0271609254182\n",
      "get_clearing_error: Clearing error: 0.0249863127511\n",
      "get_clearing_error: Clearing error: 0.0231389513063\n",
      "get_clearing_error: Clearing error: 0.0215450666756\n",
      "get_clearing_error: Clearing error: 0.0201523319911\n",
      "get_clearing_error: Clearing error: 0.0189224384643\n",
      "new search start\n",
      "get_clearing_error: Clearing error: 0.427386352295\n",
      "get_clearing_error: Clearing error: 0.0248859998298\n",
      "get_clearing_error: Clearing error: 0.0218748484399\n",
      "get_clearing_error: Clearing error: 0.0195110733295\n",
      "get_clearing_error: Clearing error: 0.0175937416741\n",
      "get_clearing_error: Clearing error: 0.0160000521685\n",
      "get_clearing_error: Clearing error: 0.0146500081088\n",
      "get_clearing_error: Clearing error: 0.0134888957715\n",
      "get_clearing_error: Clearing error: 0.0124778250623\n",
      "get_clearing_error: Clearing error: 0.0115882760364\n",
      "get_clearing_error: Clearing error: 0.0107987851888\n",
      "new search start\n",
      "get_clearing_error: Clearing error: 0.427386363801\n",
      "get_clearing_error: Clearing error: 0.00871689642559\n",
      "Minimum clearing error: 0.00871689642559\n",
      "Alpha_star: [-58.0, -438.05000441465654]\n",
      "Beta star: [956.8000117723946, -871.8000117724174]\n",
      "cleared market!\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "problem\n",
      "finished dataset 4\n"
     ]
    }
   ],
   "source": [
    "# dict of form {dataset : demand_star} \n",
    "# demand_star is a list of [control_demand, treatment_demand]\n",
    "# every dataset is mapped to the market clearing probability distribution\n",
    "demand_dict = {}\n",
    "# dict of form {dataset : # unique groups} \n",
    "num_input_groups_dict = {}\n",
    "num_output_groups_dict = {}\n",
    "problem_datasets = []\n",
    "\n",
    "start_dataset, end_dataset = 1, 5\n",
    "for d in range(start_dataset, end_dataset):\n",
    "    # load data\n",
    "    pte_df = pd.read_csv(\"data/PTE_\"+str(d)+\".csv\")\n",
    "    wtp_df = pd.read_csv(\"data/WTP_\"+str(d)+\".csv\")\n",
    "    pte_matrix = [[0, i] for i in pte_df['PTE'].values.tolist()]\n",
    "    wtp_matrix = [[0, i] for i in wtp_df['WTP'].values.tolist()]\n",
    "    \n",
    "    # solve market, add to dict\n",
    "    demand_star = simulate()\n",
    "    demand_dict[d] = demand_star\n",
    "    \n",
    "    control_probs = [demand_star_i[0] for demand_star_i in demand_star]\n",
    "    treatment_probs = [demand_star_i[1] for demand_star_i in demand_star]\n",
    "\n",
    "    # sanity check \n",
    "    # make dictionary to idenitfy subjects with same pte, wtp \n",
    "    # {(pte, wtp) : [subject numbers]} -- get groups\n",
    "    # now make sure that in each group, everyone has the same treatment and control assignment probability\n",
    "    sanity_dict = defaultdict(list)\n",
    "    for subject_num in range(len(wtp_matrix)):\n",
    "        sanity_dict[(wtp_matrix[subject_num][1], pte_matrix[subject_num][1])].append(subject_num)\n",
    "    num_input_groups_dict[d] = len(sanity_dict)\n",
    "    \n",
    "    for group in sanity_dict.values():\n",
    "        if not all([treatment_probs[group[0]] == treatment_probs[subject_num] for subject_num in group]):\n",
    "            print \"problem\"\n",
    "        if not all([control_probs[group[0]] == control_probs[subject_num] for subject_num in group]):\n",
    "            print \"problem\"\n",
    "    \n",
    "    # bounds sanity check -- some datasets appear to be problematic\n",
    "    if (min(control_probs)<epsilon) or (max(control_probs)>1-epsilon) \\\n",
    "        or (min(treatment_probs)<epsilon) or (max(treatment_probs)>1-epsilon):\n",
    "            problem_datasets.append(d)\n",
    "            print \"bounds are not correct for\", d\n",
    "    \n",
    "    # count the number of unique values of p_it -- groups of subjects with same demand\n",
    "    output_groups_dict = defaultdict(list)\n",
    "    for i, demand_i in enumerate(demand_star):\n",
    "        output_groups_dict[(demand_i[0], demand_i[1])].append(i)\n",
    "    num_output_groups_dict[d] = len(output_groups_dict)\n",
    "        \n",
    "    print \"finished dataset\", d\n",
    "    \n",
    "df_results = pd.DataFrame.from_dict(demand_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py27]",
   "language": "python",
   "name": "Python [py27]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
